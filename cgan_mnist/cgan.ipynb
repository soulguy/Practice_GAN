{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-99222dc99364>:113: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/tequila2411/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/tequila2411/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/tequila2411/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ../mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/tequila2411/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ../mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/tequila2411/.local/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "training......\n",
      "step 0: d_loss is 1.5516042, gan_loss is 1.1088674\n",
      "step 1000: d_loss is 0.6539433, gan_loss is 2.2871861\n",
      "step 2000: d_loss is 0.29743254, gan_loss is 2.899896\n",
      "step 3000: d_loss is 0.33211938, gan_loss is 3.514933\n",
      "step 4000: d_loss is 0.5104904, gan_loss is 2.806038\n",
      "step 5000: d_loss is 1.2490258, gan_loss is 2.713943\n",
      "step 6000: d_loss is 0.4718603, gan_loss is 3.9785075\n",
      "step 7000: d_loss is 0.78315187, gan_loss is 2.67983\n",
      "step 8000: d_loss is 0.7356887, gan_loss is 3.4163616\n",
      "step 9000: d_loss is 0.37008476, gan_loss is 7.969077\n",
      "step 10000: d_loss is 0.8702507, gan_loss is 4.508104\n",
      "step 11000: d_loss is 0.70774996, gan_loss is 2.9228482\n",
      "step 12000: d_loss is 0.6439607, gan_loss is 2.1061697\n",
      "step 13000: d_loss is 0.6043226, gan_loss is 2.1176314\n",
      "step 14000: d_loss is 0.7700485, gan_loss is 3.1668963\n",
      "step 15000: d_loss is 0.60754323, gan_loss is 3.8414917\n",
      "step 16000: d_loss is 0.4845062, gan_loss is 2.6146522\n",
      "step 17000: d_loss is 0.6589722, gan_loss is 2.1210778\n",
      "step 18000: d_loss is 0.58145994, gan_loss is 2.36837\n",
      "step 19000: d_loss is 0.8848453, gan_loss is 2.3087928\n",
      "step 20000: d_loss is 0.83777344, gan_loss is 1.7782629\n",
      "step 21000: d_loss is 0.98225474, gan_loss is 1.8224673\n",
      "step 22000: d_loss is 0.7312952, gan_loss is 1.8115296\n",
      "step 23000: d_loss is 0.9232663, gan_loss is 1.6572416\n",
      "step 24000: d_loss is 1.0651474, gan_loss is 1.6270943\n",
      "step 25000: d_loss is 1.1160479, gan_loss is 1.6537216\n",
      "step 26000: d_loss is 0.7108964, gan_loss is 2.5378878\n",
      "step 27000: d_loss is 1.2771988, gan_loss is 1.3827648\n",
      "step 28000: d_loss is 1.6548355, gan_loss is 1.9063541\n",
      "step 29000: d_loss is 1.3358996, gan_loss is 1.2743497\n",
      "step 30000: d_loss is 1.2731645, gan_loss is 1.3327725\n",
      "step 31000: d_loss is 1.0912337, gan_loss is 1.3460062\n",
      "step 32000: d_loss is 1.4723428, gan_loss is 1.4603558\n",
      "step 33000: d_loss is 1.2642941, gan_loss is 1.1235244\n",
      "step 34000: d_loss is 1.1289124, gan_loss is 1.2776607\n",
      "step 35000: d_loss is 1.1884913, gan_loss is 1.2539828\n",
      "step 36000: d_loss is 1.442243, gan_loss is 1.1657704\n",
      "step 37000: d_loss is 1.5788817, gan_loss is 1.3050618\n",
      "step 38000: d_loss is 1.0661888, gan_loss is 1.27793\n",
      "step 39000: d_loss is 1.3519742, gan_loss is 1.1470356\n",
      "step 40000: d_loss is 1.1133476, gan_loss is 1.0275526\n",
      "step 41000: d_loss is 1.3349097, gan_loss is 1.3691711\n",
      "step 42000: d_loss is 1.350922, gan_loss is 1.0779483\n",
      "step 43000: d_loss is 1.0144413, gan_loss is 1.4590871\n",
      "step 44000: d_loss is 1.4991944, gan_loss is 1.3533064\n",
      "step 45000: d_loss is 1.3763331, gan_loss is 1.5272515\n",
      "step 46000: d_loss is 1.0716211, gan_loss is 1.3419724\n",
      "step 47000: d_loss is 1.0724237, gan_loss is 1.4710608\n",
      "step 48000: d_loss is 1.6101015, gan_loss is 0.8543203\n",
      "step 49000: d_loss is 1.3006036, gan_loss is 1.3086793\n",
      "step 50000: d_loss is 1.0484339, gan_loss is 1.5589495\n",
      "step 51000: d_loss is 0.9813681, gan_loss is 2.04997\n",
      "step 52000: d_loss is 1.1487737, gan_loss is 1.1446657\n",
      "step 53000: d_loss is 0.95733154, gan_loss is 1.3613158\n",
      "step 54000: d_loss is 1.2311133, gan_loss is 1.361031\n",
      "step 55000: d_loss is 1.1504252, gan_loss is 1.1820734\n",
      "step 56000: d_loss is 1.1446115, gan_loss is 1.5787997\n",
      "step 57000: d_loss is 1.08924, gan_loss is 1.3741589\n",
      "step 58000: d_loss is 1.1328591, gan_loss is 1.3940653\n",
      "step 59000: d_loss is 1.2422655, gan_loss is 1.1065297\n",
      "step 60000: d_loss is 1.0985332, gan_loss is 1.1051884\n",
      "step 61000: d_loss is 1.0767841, gan_loss is 1.130197\n",
      "step 62000: d_loss is 1.4567909, gan_loss is 1.7615557\n",
      "step 63000: d_loss is 1.6872412, gan_loss is 1.2620481\n",
      "step 64000: d_loss is 1.3559849, gan_loss is 1.3100948\n",
      "step 65000: d_loss is 1.1163862, gan_loss is 1.2336471\n",
      "step 66000: d_loss is 1.7838969, gan_loss is 1.2104487\n",
      "step 67000: d_loss is 1.5632915, gan_loss is 0.91461724\n",
      "step 68000: d_loss is 1.1901413, gan_loss is 1.3705828\n",
      "step 69000: d_loss is 1.3552275, gan_loss is 1.2236091\n",
      "step 70000: d_loss is 1.5713229, gan_loss is 0.79948616\n",
      "step 71000: d_loss is 1.0052737, gan_loss is 1.3059795\n",
      "step 72000: d_loss is 1.3891424, gan_loss is 1.5691283\n",
      "step 73000: d_loss is 1.5033714, gan_loss is 1.1155987\n",
      "step 74000: d_loss is 1.4519128, gan_loss is 0.96846485\n",
      "step 75000: d_loss is 1.2018172, gan_loss is 1.0021547\n",
      "step 76000: d_loss is 1.5049071, gan_loss is 1.5344856\n",
      "step 77000: d_loss is 1.1740332, gan_loss is 1.2622066\n",
      "step 78000: d_loss is 1.3649517, gan_loss is 1.8412986\n",
      "step 79000: d_loss is 1.3239536, gan_loss is 1.2183933\n",
      "step 80000: d_loss is 1.7138593, gan_loss is 1.5036235\n",
      "step 81000: d_loss is 1.2454134, gan_loss is 2.0192897\n",
      "step 82000: d_loss is 1.1894574, gan_loss is 1.29709\n",
      "step 83000: d_loss is 1.1893343, gan_loss is 1.2596309\n",
      "step 84000: d_loss is 1.5971835, gan_loss is 1.5067961\n",
      "step 85000: d_loss is 1.5116985, gan_loss is 0.9963316\n",
      "step 86000: d_loss is 1.2444601, gan_loss is 1.3185302\n",
      "step 87000: d_loss is 1.37484, gan_loss is 1.0531933\n",
      "step 88000: d_loss is 1.2868491, gan_loss is 1.3270764\n",
      "step 89000: d_loss is 1.2526202, gan_loss is 1.2105494\n",
      "step 90000: d_loss is 1.5707662, gan_loss is 1.4753418\n",
      "step 91000: d_loss is 1.5202479, gan_loss is 0.85013103\n",
      "step 92000: d_loss is 1.2099707, gan_loss is 1.3347425\n",
      "step 93000: d_loss is 1.5335721, gan_loss is 0.9856621\n",
      "step 94000: d_loss is 1.3792641, gan_loss is 0.81112164\n",
      "step 95000: d_loss is 1.0655147, gan_loss is 1.6597859\n",
      "step 96000: d_loss is 1.2487471, gan_loss is 1.0472286\n",
      "step 97000: d_loss is 2.0586872, gan_loss is 1.068293\n",
      "step 98000: d_loss is 1.5732327, gan_loss is 1.0928481\n",
      "step 99000: d_loss is 1.2182627, gan_loss is 1.752583\n",
      "step 99999: d_loss is 1.2960703, gan_loss is 0.8947214\n"
     ]
    }
   ],
   "source": [
    "# %load cgan.py\n",
    "#%load cgan.py\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import logging\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os\n",
    "\n",
    "if not os.path.exists('./log'):\n",
    "    os.mkdir('./log')\n",
    "if not os.path.exists('./out'):\n",
    "    os.mkdir('./out')\n",
    "\n",
    "def get_logger(filepath,level=logging.INFO):\n",
    "    \n",
    "    logger = logging.getLogger(__name__)\n",
    "    logger.setLevel(level)\n",
    "\n",
    "    # create a file handler\n",
    "    handler = logging.FileHandler(filepath)\n",
    "    handler.setLevel(logging.INFO)\n",
    "\n",
    "    # create a logging format\n",
    "    #formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    #handler.setFormatter(formatter)\n",
    "\n",
    "    # add the handlers to the logger\n",
    "    logger.addHandler(handler)\n",
    "    return logger\n",
    "\n",
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "    return fig\n",
    "\n",
    "def random_data(row,column):\n",
    "    return np.random.uniform(-1., 1., size=[row, column])\n",
    "\n",
    "def weight_variable(shape, stddev=0.1):\n",
    "    initial = tf.truncated_normal(shape, stddev=stddev)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape, bais=0.1):\n",
    "    initial = tf.constant(bais, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "g_w1 = weight_variable([110,128])\n",
    "g_b1 = bias_variable([128])\n",
    "g_w2 = weight_variable([128,784])\n",
    "g_b2 = bias_variable([784])\n",
    "\n",
    "g_param = [g_w1,g_w2,g_b1,g_b2]\n",
    "\n",
    "d_w1 = weight_variable([794,128])\n",
    "d_b1 = bias_variable([128])\n",
    "d_w2 = weight_variable([128,1])\n",
    "d_b2 = bias_variable([1])\n",
    "\n",
    "d_param = [d_w1,d_w2,d_b1,d_b2]\n",
    "\n",
    "def d_network(x,y):\n",
    "    #加入condition\n",
    "    condition_x = tf.concat(values=[x,y],axis=1)\n",
    "\n",
    "    d_1 = tf.nn.relu(tf.matmul(condition_x,d_w1)+d_b2)\n",
    "    d_out = tf.matmul(d_1,d_w2)+d_b2\n",
    "\n",
    "    return d_out\n",
    "\n",
    "def g_network(x,y):\n",
    "    #加入condition\n",
    "    condition_x = tf.concat(values=[x,y],axis=1)\n",
    "\n",
    "    g_1 = tf.nn.relu(tf.matmul(condition_x,g_w1)+g_b1)\n",
    "    g_out = tf.matmul(g_1,g_w2)+g_b2\n",
    "\n",
    "    return g_out\n",
    "\n",
    "num_class = 10\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,num_class])\n",
    "z = tf.placeholder(tf.float32,[None,100])\n",
    "\n",
    "d_out = d_network(x,y)\n",
    "\n",
    "g_out = g_network(z,y)\n",
    "gan_out = d_network(g_out,y)\n",
    "\n",
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=d_out,labels=tf.ones_like(d_out)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=gan_out, labels=tf.zeros_like(gan_out)))\n",
    "d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "gan_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=gan_out, labels=tf.ones_like(gan_out)))\n",
    "\n",
    "d_train = tf.train.AdamOptimizer().minimize(d_loss, var_list=d_param)\n",
    "gan_train = tf.train.AdamOptimizer().minimize(gan_loss, var_list=g_param)\n",
    "\n",
    "batch_size = 128\n",
    "max_step = 100000\n",
    "mnist = input_data.read_data_sets('../mnist', one_hot=True)\n",
    "logger = get_logger(\"./log/info.log\")\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(\"training......\")\n",
    "    i = 0\n",
    "    for step in range(max_step):\n",
    "        batch_real,labels_real = mnist.train.next_batch(batch_size)\n",
    "        batch_fake = random_data(batch_size,100)\n",
    "\n",
    "        _,d_loss_train = sess.run([d_train,d_loss],feed_dict={x:batch_real, z:batch_fake, y:labels_real})\n",
    "        _,gan_loss_train = sess.run([gan_train,gan_loss],feed_dict={z:batch_fake,y:labels_real})\n",
    "\n",
    "        if step%1000 == 0 or step == max_step-1:\n",
    "\n",
    "            logger.info(\"step %s: d_loss is %s, gan_loss is %s\" % (step, d_loss_train, gan_loss_train))\n",
    "            print(\"step %s: d_loss is %s, gan_loss is %s\" % (step, d_loss_train, gan_loss_train))\n",
    "\n",
    "    labels_test = np.zeros([16,num_class],dtype=np.float32)\n",
    "    labels_test[:,5] = 1\n",
    "    samples = sess.run(g_out, feed_dict={z: random_data(16, 100),y:labels_test})\n",
    "\n",
    "    fig = plot(samples)\n",
    "    plt.savefig('out/{}.png'.format(str(i).zfill(3)), bbox_inches='tight')\n",
    "    i += 1\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
